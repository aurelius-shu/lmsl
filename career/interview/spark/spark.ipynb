{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 什么是Spark？\n",
    "```\n",
    "简单理解，Spark是在Hadoop基础上的改进，是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行计算框架，Spark基于map reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为什么要学Spark?\n",
    "```\n",
    "基于MapReduce的计算引擎通常会将中间结果输出到磁盘上，进行存储和容错。出于任务管道承接的考虑，当一些查询翻译到MapReduce任务时，往往会产生多个Stage，而这些串联的Stage又依赖于底层文件系统（如HDFS）来存储每一个Stage的输出结果。\n",
    "Spark是MapReduce的替代方案，而且兼容HDFS、Hive，可融入Hadoop的生态系统，以弥补MapReduce的不足。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark有什么特性？\n",
    "```\n",
    "1、高效性\n",
    "运行速度提高100倍。Apache Spark使用最先进的DAG调度程序，查询优化程序和物理执行引擎，实现批量和流式数据的高性能。\n",
    "2、易用性\n",
    "Spark支持Java、Python和Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的shell，可以非常方便地在这些shell中使用Spark集群来验证解决问题的方法。\n",
    "3、通用性\n",
    "Spark提供了统一的解决方案。Spark可以用于批处理、交互式查询（Spark SQL）、实时流处理（Spark Streaming）、机器学习（Spark MLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝使用。Spark统一的解决方案非常具有吸引力，毕竟任何公司都想用统一的平台去处理遇到的问题，减少开发和维护的人力成本和部署平台的物力成本。\n",
    "4、兼容性\n",
    "Spark可以非常方便地与其他的开源产品进行融合。比如，Spark可以使用Hadoop的YARN和Apache Mesos作为它的资源管理和调度器，器，并且可以处理所有Hadoop支持的数据，包括HDFS、HBase和Cassandra等。这对于已经部署Hadoop集群的用户特别重要，因为不需要做任何数据迁移就可以使用Spark的强大处理能力。Spark也可以不依赖于第三方的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架，这样进一步降低了Spark的使用门槛，使得所有人都可以非常容易地部署和使用Spark。此外，Spark还提供了在EC2上部署Standalone的Spark集群的工具。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark生态圈介绍\n",
    "```\n",
    "Spark力图整合机器学习（MLib）、图算法（GraphX）、流式计算（Spark Streaming）和数据仓库（Spark SQL）等领域，通过计算引擎Spark，弹性分布式数据集（RDD），架构出一个新的大数据应用平台。\n",
    "Spark生态圈以HDFS、S3、Techyon为底层存储引擎，以Yarn、Mesos和Standlone作为资源调度引擎；使用Spark，可以实现MapReduce应用；基于Spark，Spark SQL可以实现即席查询，Spark Streaming可以处理实时应用，MLib可以实现机器学习算法，GraphX可以实现图计算，SparkR可以实现复杂数学计算。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark与Hadoop的对比\n",
    "```\n",
    "Spark的中间数据放到内存中，对于迭代运算效率更高。Spark更适合于迭代运算比较多的ML和DM运算。因为在Spark里面，有RDD的抽象概念。所以，Spark比Hadoop更通用。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spark的组成有哪些？\n",
    "```\n",
    "Spark组成(BDAS)：全称伯克利数据分析栈，通过大规模集成算法、机器、人之间展现大数据应用的一个平台。也是处理大数据、云计算、通信的技术解决方案。\n",
    "它的主要组件有：\n",
    "SparkCore：将分布式数据抽象为弹性分布式数据集（RDD），实现了应用任务调度、RPC、序列化和压缩，并为运行在其上的上层组件提供API。\n",
    "SparkSQL：Spark Sql 是Spark来操作结构化数据的程序包，可以让我使用SQL语句的方式来查询数据，Spark支持 多种数据源，包含Hive表，parquest以及JSON等内容。\n",
    "SparkStreaming：是Spark提供的实时数据进行流式计算的组件。\n",
    "MLlib：提供常用机器学习算法的实现库。\n",
    "GraphX：提供一个分布式图计算框架，能高效进行图计算。\n",
    "BlinkDB：用于在海量数据上进行交互式SQL的近似查询引擎。\n",
    "Tachyon：以内存为中心高容错的的分布式文件系统。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark的工作流程是什么样的呢？\n",
    "```\n",
    "通俗的解释就是：Spark是为了处理数据而生的平台，用一个比喻来形容它是餐馆。餐馆搭建好了后，就会有顾客，顾客的各种需求都得有人去处理，那么这时的Master就像是服务员，负责了解顾客的要求并把需求按照一定规律分配给厨师（Worker），这个顾客的需求就是一个APP，但这个APP不止包括了一个菜（job），整个订单里有很多个job，每个job都得由这些厨师处理，厨师的手就像是具体处理的Executor，负责所有的包括shuffle啊，filter啊，map啊，reduce等等具体的对原材料（RDD）的处理。driver就像是懒惰的厨师长，worker向它申请资源，同时它负责接收下面的人处理好的半成品材料或者完成品的菜品，但它自己并不干具体的活，如果是别人处理好的半成品，driver就将它分配给它认为有空的人接着处理（可能是map后要reduce的东西），直到目前的stage结束得到具体想要的结果，如果是直接就是想要的数据形式（一个job的完成），那么driver就通知master收货并反馈给顾客（可能是python程序，scala程序等等）。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apache Spark和Apache Storm之间有什么差异，用户应该根据什么来加以选择？\n",
    "```\n",
    "Apache Spark是一个内存中的分布式数据分析平台- 主要针对加快批量分析工作,反复机器学习的工作，交互式查询和图形处理。一个最主要区别是Spark使用弹性分布式数据集（RDD）。RDD是通过并行运算符来进行计算，并根据定义它是一成不变的。RDD允许Spark基于谱系信息容错的独特的形式。如果你对执行Hadoop MapReduce作业更快，那么Spark是一个很好的选择（即使在这里需要考虑内存的因素）。\n",
    "Apache Storm是专注于流处理或者一些所谓复杂事件的处理。Storm实现容错的方法进行计算或者以流水线的方式多次计算一个事件，由于Storm进入一个需要特定格式的系统，那么可能导致它转换为一个非结构化的数据。\n",
    "Storm和Spark存在相当不同的使用情况。Storm和Spark流更多是类似“苹果和苹果”比较。由于Spark的SSD本身是不可变的，Spark流实现在用户定义的时间间隔“定量”来实现更新，得到改造成自己的RDD的方法，从而Spark的并行操作人员可以对这些RDD进行计算。这是与Storm处理每个事的不同之处。\n",
    "这两种技术之间的一个主要区别是，Spark进行数据的并行计算，而Storm则是任务的并行计算。无论是那种方法，都有它表现价值的一方面。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDD的核心概念是什么？\n",
    "```\n",
    "Client：客户端进程，负责提交作业到Master。\n",
    "Master:Standalone模式中主控节点，负责接收Client提交的作业，管理Worker，并命令Worker启动分配Driver的资源和启动Executor的资源。\n",
    "Worker：Standalone模式中slave节点上的守护进程，负责管理本节点的资源，定期向Master汇报心跳，接收Master的命令，启动Driver和Executor。\n",
    "Driver：一个Spark作业运行时包括一个Driver进程，也是作业的主进程，负责作业的解析、生成Stage并调度Task到Executor上。包括DAGScheduler，TaskScheduler。\n",
    "Executor：即真正执行作业的地方，一个集群一般包含多个Executor，每个Executor接收Driver的命令Launch Task，一个Executor可以执行一到多个Task。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDD有哪些常见术语?\n",
    "```\n",
    "DAGScheduler：实现将Spark作业分解成一到多个Stage，每个Stage根据RDD的Partition个数决定Task的个数，然后生成相应的Task set放到TaskScheduler中。\n",
    "TaskScheduler：实现Task分配到Executor上执行。\n",
    "Task：运行在Executor上的工作单元。\n",
    "Job：SparkContext提交的具体Action操作，常和Action对应。\n",
    "Stage：每个Job会被拆分很多组任务(task)，每组任务被称为Stage，也称TaskSet。\n",
    "RDD：Resilient Distributed Datasets的简称，弹性分布式数据集，是Spark最核心的模块和类。\n",
    "Transformation/Action：SparkAPI的两种类型;Transformation返回值还是一个RDD，Action返回值不少一个RDD，而是一个Scala的集合;所有的Transformation都是采用的懒策略，如果只是将Transformation提交是不会执行计算的，计算只有在Action被提交时才会被触发。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDD提供了哪些操作？\n",
    "```\n",
    "RDD提供了两种类型的操作：\n",
    "transformation和action\n",
    "1. transformation是得到一个新的RDD，方式很多，比如从数据源生成一个新的RDD，从RDD生成一个新的RDD\n",
    "2. action是得到一个值，或者一个结果(直接将RDD cache到内存中)\n",
    "3. 所有的transformation都是采用的懒策略，就是如果只是将transformation提交是不会执行计算的，计算只有在action被提交的时候才被触发。\n",
    "DataFrame：带有Schema信息的RDD，主要是对结构化数据的高度抽象。\n",
    "DataSet：结合了DataFrame和RDD两者的优势，既允许用户很方便的操作领域对象，又具有SQL执行引擎的高效表现。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDD中关于转换(transformation)与动作(action)有什么区别？\n",
    "```\n",
    "transformation会生成新的RDD，而后者只是将RDD上某项操作的结果返回给程序，而不会生成新的RDD;无论执行了多少次transformation操作，RDD都不会真正执行运算(记录lineage)，只有当action操作被执行时，运算才会触发。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDD 与 DSM的最大不同是什么？\n",
    "```\n",
    "RDD只能通过粗粒度转换来创建，而DSM则允许对每个内存位置上数据的读和写。在这种定义下，DSM不仅包括了传统的共享内存系统，也包括了像提供了共享 DHT(distributed hash table) 的 Piccolo 以及分布式数据库等。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark 消费Kafka,分布式的情况下，如何保证消息的顺序？\n",
    "\n",
    "Kafka分布式的单位是Partition，如何保证消息有序，需要分以下几个条件讨论：\n",
    "\n",
    "- 同一个Partition用一个 write ahead log 组织，所以可以保证FIFO的顺序。\n",
    "- 不同Partition之间不能保证顺序但是绝大多数用户可以通过 message key 来定义，因为同一个key的 message 可以保证只发送到同一个Partition。如果说key是user id， table row id 等等，所以同一个user 或者同一个record 的消息永远只会发送到同一个 Partition 上，保证了同一个 user 或 record 的顺序。\n",
    "- 当然，如果你有 key skewnes就有些麻烦，需要谨慎处理。\n",
    "```\n",
    "实际情况中，(1)不关注顺序的业务大量存在，队列无序不代表消息无序。(2)我们不保证队列的全局有序，但可以保证消息的局部有序，举个例子:保证来自同一个order id 的消息，是有序的。Kafka中发送1条消息的时候,可以指定(topic,partition,key) 3个参数。partition和key是可选的，如果你指partition，那就是所有消息发往同一个partition，就是有序的，而且在消费端,Kafka保证，1个partition只能被一个consumer消费。或者你指定key(比如order id)，具有同一个key的所有消息，会发往同一个partition，也就是有序。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对于Spark中的数据倾斜问题好的法案\n",
    "```\n",
    " 简单一句: Spark 数据倾斜的几种场景以及对应的解决方案，包括避免数据源倾斜，调整并行度，使用自定义 Partitioner，使用 Map 侧 Join 代替 Reduce 侧  Join（内存表合并），给倾斜 Key 加上随机前缀等。\n",
    "\n",
    "什么是数据倾斜 对 Spark/Hadoop 这样的大数据系统来讲，数据量大并不可怕，可怕的是数据倾斜。数据倾斜指的是，并行处理的数据集中，某一部分（如 Spark 或 Kafka 的一个 Partition）的数据显著多于其它部分，从而使得该部分的处理速度成为整个数据集处理的瓶颈（木桶效应）。\n",
    "\n",
    "数据倾斜是如何造成的 在 Spark 中，同一个 Stage 的不同 Partition 可以并行处理，而具有依赖关系的不同 Stage 之间是串行处理的。假设某个 Spark Job 分为 Stage 0和 Stage 1两个 Stage，且 Stage 1依赖于 Stage 0，那 Stage 0完全处理结束之前不会处理Stage 1。而 Stage 0可能包含 N 个 Task，这 N 个 Task 可以并行进行。如果其中 N-1个 Task 都在10秒内完成，而另外一个 Task 却耗时1分钟，那该 Stage 的总时间至少为1分钟。换句话说，一个 Stage 所耗费的时间，主要由最慢的那个 Task 决定。由于同一个Stage内的所有 Task 执行相同的计算，在排除不同计算节点计算能力差异的前提下，不同 Task 之间耗时的差异主要由该 Task 所处理的数据量决定。\n",
    "\n",
    "具体解决方案 ：\n",
    "\n",
    "1. 调整并行度分散同一个 Task 的不同 Key: Spark 在做 Shuffle 时，默认使用 HashPartitioner对数据进行分区。如果并行度设置的不合适，可能造成大量不相同的 Key 对应的数据被分配到了同一个 Task 上，造成该 Task 所处理的数据远大于其它 Task，从而造成数据倾斜。如果调整 Shuffle 时的并行度，使得原本被分配到同一 Task 的不同 Key 发配到不同 Task 上处理，则可降低原 Task 所需处理的数据量，从而缓解数据倾斜问题造成的短板效应。图中左边绿色框表示 kv 样式的数据，key 可以理解成 name。可以看到 Task0 分配了许多的 key，调整并行度，多了几个 Task，那么每个Task处理的数据量就分散了。\n",
    "\n",
    "2. 自定义Partitioner: 使用自定义的 Partitioner（默认为 HashPartitioner），将原本被分配到同一个 Task 的不同 Key 分配到不同 Task，可以拿上图继续想象一下，通过自定义 Partitioner 可以把原本分到 Task0 的 Key 分到 Task1，那么 Task0 的要处理的数据量就少了。 \n",
    "\n",
    "3. 将 Reduce side（侧） Join 转变为 Map side（侧） Join: 通过 Spark 的 Broadcast 机制，将 Reduce 侧 Join 转化为 Map 侧 Join，避免 Shuffle 从而完全消除 Shuffle 带来的数据倾斜。可以看到 RDD2 被加载到内存中了。\n",
    "\n",
    "4. 为 skew 的 key 增加随机前/后缀: 为数据量特别大的 Key 增加随机前/后缀，使得原来 Key 相同的数据变为 Key 不相同的数据，从而使倾斜的数据集分散到不同的 Task 中，彻底解决数据倾斜问题。Join 另一则的数据中，与倾斜 Key 对应的部分数据，与随机前缀集作笛卡尔乘积，从而保证无论数据倾斜侧倾斜 Key 如何加前缀，都能与之正常 Join。\n",
    "\n",
    "5. 大表随机添加 N 种随机前缀，小表扩大 N 倍: 如果出现数据倾斜的 Key 比较多，上一种方法将这些大量的倾斜 Key 分拆出来，意义不大（很难一个 Key 一个 Key 都加上后缀）。此时更适合直接对存在数据倾斜的数据集全部加上随机前缀，然后对另外一个不存在严重数据倾斜的数据集整体与随机前缀集作笛卡尔乘积（即将数据量扩大 N 倍），可以看到 RDD2 扩大了 N 倍了，再和加完前缀的大数据做笛卡尔积。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
